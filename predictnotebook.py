# -*- coding: utf-8 -*-
"""PredictNotebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11a0E4p8pXI9s1EQkxV1YEbRB6HIxM0UP
"""

import pickle
import numpy as np
import pandas as pd
import lightgbm as lgb
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error
import os
from config import TRAINED_MODEL_PATH

# Load the model using pickle

trained_model_file = os.path.join(TRAINED_MODEL_PATH, "trained_model.pkl")

# Load the model using pickle
with open(trained_model_file, "rb") as file:
    loaded_model = pickle.load(file)

print("Model loaded successfully")

#Load the optimal parameters and features found in model training
model_metadata_file = os.path.join(TRAINED_MODEL_PATH, "model_metadata.pkl")

# Load the optimal parameters and features found in model training
with open(model_metadata_file, "rb") as pkl_file:
    data = pickle.load(pkl_file)

imp_features = data["imp_features"]
best_params = data["best_params"]

print("Important Features:", imp_features)
print("Best Parameters:", best_params)

# Construct the path to the processed test data file
processed_test_file = os.path.join(PROCESSED_DATA_PATH, "processed_test_data.pkl")

# Load the test dataset
with open(processed_test_file, "rb") as file:
    test_df = pickle.load(file)

print("Test set loaded successfully")

#Now drop features from the testing set, only keeping omptimal features
target = "usage_kWh"
X_test = test_df[imp_features]
y_test = test_df[target]

def rmsle(y_true, y_pred):
  # Good article on RMSLE: https://medium.com/analytics-vidhya/root-mean-square-log-error-rmse-vs-rmlse-935c6cc1802a
  y_pred = np.clip(y_pred, 0, None) #Any value in y_pred that is less than 0 will be replaced with 0
  return np.sqrt(mean_squared_error(np.log1p(y_true), np.log1p(y_pred)))

y_pred = loaded_model.predict(X_test)
y_pred = np.clip(y_pred, 0, None)
score = rmsle(y_test, y_pred)
print("The root mean squared percentage error of the model is:", round(score,3))

results = pd.DataFrame({'Actual': np.expm1(y_test), 'Predicted': np.expm1(y_pred)})

plt.figure(figsize=(12, 6))
days = 21
# plt.plot(results.index, results['Actual'], label='Actual', color='blue', linewidth=2)
# plt.plot(results.index, results['Predicted'], label='Predicted', color='orange', linewidth=2)
plt.plot(results.index[:days*24], results['Actual'][:days*24], label='Actual', color='blue', linewidth=2)
plt.plot(results.index[:days*24], results['Predicted'][:days*24], label='Predicted', color='orange', linewidth=2)

# Adding title and labels
plt.title('Actual vs Predicted Values', fontsize=16)
plt.xlabel('Observation Index', fontsize=12)
plt.ylabel('Usage (kWh)', fontsize=12)

# Adding legend and grid for better readability
plt.legend()

# Display the plot
plt.tight_layout()
plt.show()

predicted_kWh = round(np.sum(y_pred),2)
actual_kWh = round(np.sum(y_test),2)

print(f"Predicted kWh: {predicted_kWh}")
print(f"Actual kWh: {actual_kWh}")

(actual_kWh-predicted_kWh)/actual_kWh

"""#Conclusion

The results of this exercise, while showing potential, fall short of being satisfactory from the perspective of an energy professional. A final evaluation of the predicted target variable against a year-long test dataset yielded an RMSLE of 0.15. The RMSLE indicates that, on average, the predicted values differ from the actual values by a factor of 15% on a logarithmic scale. The total predicted energy usage deviated from the actual usage by approximately 300 kWh, which represents a 14% difference from the actual total.

The predicted data successfully captured the timing of energy usage peaks but failed to match their magnitude. While this alignment with the timing of peaks may have some utility, it is highly desireable for the magnitude of the predictions to align closely with actual measurements. Additionally, the model performed well on lower values of energy usage but struggled to capture spikes.

### Nature of the Dataset
The nature of the dataset itself could contribute to the challenges in modeling. This data represents my personal energy usage, which is influenced by my irregular schedule and the fact that I live alone. Patterns are often more systematic and easier to identify for commercial buildings or data aggregated from multiple buildings. My personal energy usage trends may be more random and less predictable. These factors introduce a high degree of variability, making it more difficult for the selected machine learning scheme to find consistent patterns or accurately predict usage.

###Next Steps

The results could likely be improved by incorporating an ensemble of models, including neural networks, to better capture nonlinear relationships and complex patterns in the data.

"""